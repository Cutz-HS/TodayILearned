[python-analysis]▶
1. stat+math+CS ▶ ML알고리즘 (수학, 통계적 기반)
- KNN/Kmeans/SVM/Bayes theory/NN
- lib(numpy, pandas, matplotlib, scipy)
 -배열: 동일한 나열이 여러개 나열
 -벡터: 위치벡터, 방향과 크기 / 차원

2. Correlation: 데이터 변수간의 관계파악 / 종속관계파악
 ▶ 상관관계가 deep -> 차원축소(PCA, 요인분석)

3. ML: 연산 -> 정확/속도
 - 연산결과 -> 학습 -> 모델 -> 예측

4. implicit / explicit programming
▶ 묵시적 프로그래밍: not if (ML)/모든 input에 output return
▶ 정교한 프로그래밍: if // 가능하다면, 이 쪽이 나을 수도 있다.

5. 퍼셉트론
▶ 초기AI / 분포된 데이터에 분류선을 그어 데이터 분류
  - 한계점: 비슷한 성향에서 분류를 가를 때 한계가 존재
▶ 이러한 한계를 극복하기 위해 multi perceptron -> NN(신경망)
  - 다만 성능의 한계때문에, 역전파 개념 등장

6. SVM: 딥러닝 등장 전, 분류 예측 알고리즘으로 이용
 - Vanishing Gradient (X) 극한 -> (0)
 - 뎁스가 증가되는 딥러닝 RVM -> CNN, RNN, GAN(적대신경망)

7. KNN(K-nearest neighbor)
▶ 최근접 이웃, K값을 얼마나 줘야 하는 지가 관건, K는 새로운 데이터가 등장했을 때,
    그룹화시키는 수 // 변수에 따라 value가 달라질 수 있기 때문에, 정규화

8. 결정트리: 엔트로피 개념 -복잡도(0~1)
▶ 엔트로피: 복잡도, 혼탁정도, 투명도의 척도 -> 엔트로피 계산 -> 복잡도
 - 분류 후에는 엔트로피 감소, 어떠한 feature로 쪼갤 것인가의 문제 -> 비교 전/후 (복잡도의 차이가 max)
 -> 의사결정트리: 엔트로피를 줄이는 방향으로 질문 // 분류

9. 이상치 제거
▶ IQRX1.5 이상 -> 제거

10. 연관규칙
▶ A priori Algorithm -> 강력한 규칙을 바탕으로 연산
- 유사상황(KNN알고리즘)
- 예측: 규칙성
- 서술: 클러스터링/연관규칙/규칙
- 마트에서 구매한 트랜젝션 리스트 -> 특정아이템이 함께하는 규칙을 찾기

11. 데이터 과정
▶ selection -> preprocessing -> trasformation -> datamining -> interpretation/Evlauation

12. 분류
 - 레코드: 여러 속성(attribute, feature) 구성, 하나의 클래스(결과값, 레이블)
 - 훈련집합
 - test집합(보통 7:3)

13. 클러스터링: 클러스터 그룹 // 클러스터 개수 지정만 할뿐, 비지도학습

14. matplotlib.pyplot as plt
plt.plot(list, list, 'ro')
plt.show()

15. enumerate -> index, value