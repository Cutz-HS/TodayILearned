▶[wisenut]
1. bicrawler: 와이즈넛에서 제공하는 리눅스 수집기
 - 클렌징과 필터를 통해 추출하여 scd에 저장 -> 가공
 - wise tea -> 주제 마이닝
 - bic analysier -> 형태소분석, lsp 알고리즘 등을 실행하여 분석

2. 데이터수집과정
 ▶ 수집: 대상확인 / 인프라 / crawler 모니터링 
  - 네이버와 같은 경우, 블로그-카페-지식인-뉴스 등으로 가능

3. VM
 - 가상시스템을 가져와서 와이즈넛에서 준비한 리눅스환경 설치

4. DB설치
 - 크롤링 데이터를 DB에 저장할 수도 있기 때문에, postgreSQL 설치
 - postgreSQL - > corlib -> postsreSQLDB

5. 리눅스
 - su -> 계정id.변경
 - cd / -> 루트디렉토리로
 - cd /s -> 관리자권한
 - ctrl + shift + c/v -> 리눅스 내에서 컨씨컨브이
 - tab -> 자동완성(오타 줄이기로 활용)
 - ctrl+c -> 종료 처맨드
 - gg -> 맨 처음
 - ctrl+f -> 1페이지
 - ctrl+d -> 1페이지 뒤
 - sudo kill -9 process ID

6. vi에디터
 - j k 이동 // i: 현재 커서에 입력모드 // a: 다음커서에 입력모드
 - 명령모드에서 x 삭제 // :q wq는 종료, 저장후 종료 // esc 명령모드로

7. crawler설치
 - 자바설치 -> path설정
 - wisenut
 - cmanager -> monitoring - host 설정
 - properties - 패치 적용
 - header: 브라우저(다중교환: 차단방지)

8. firefox
 - localhost: 8080 admin/admin
 - 목록 수집 URL패턴

9. html 설정
 - 목록수집 -> 수집할 툴 관리
 - jsoup을 필요한 곳에 설정
 - 블로그: 제목/본문내용/치환URL/본문영역 // 이동공간:제목/본문

10. try.jsoup.org
 ▶ jsoup test 공간

11. https://regexr.com/
 ▶ 정규식표현 test공간

12. 매니저켜기
 ▶ 크롤러를 local host에 연결시켜주는 역할(필수)
 home/wisenut/bicrawler/manager/batch
 ./manager.sh start
 - ps -ef | grep bic (bic으로 시작하는 프로세스 확인)
 - 서버: /batch ./server.sh start
 - 로그확인 /log tail -f crawler.log

13. jsoup
 ▶ 프레임이 있을 경우, 프레임 안으로 접근! (다음블로그)